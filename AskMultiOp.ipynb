{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.datasets\n",
    "from sklearn.datasets import fetch_openml\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from lightgbm import LGBMClassifier\n",
    "from skopt.optimizer import Optimizer\n",
    "from skopt.space import Integer,Real\n",
    "import warnings\n",
    "from tqdm.notebook import tqdm\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = fetch_openml(name='credit-g')\n",
    "cat_cols = ['checking_status','credit_history','purpose','savings_status','savings_status','personal_status','other_parties','employment',\n",
    "           'property_magnitude','other_payment_plans','housing','existing_credits','job','class']\n",
    "df = data.frame\n",
    "for col in cat_cols:\n",
    "    df[col] = pd.factorize(df[col])[0]\n",
    "x_cols = [col for col in df.columns if col not in ['class']]\n",
    "x = df[x_cols]\n",
    "y = df['class']\n",
    "cat_cols.remove('class')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def myscore(y_pred,y):\n",
    "    return roc_auc_score(y,y_pred)\n",
    "\n",
    "def f(para,seed=0):\n",
    "\n",
    "        \n",
    "    leaves,lr,n_estimators,child,subsample,colsample = para[0], 0.1, para[1], para[2], para[3], para[4]\n",
    "    \n",
    "    x_train, x_test, y_train,y_test = train_test_split(x, y, test_size=0.3, random_state=seed)\n",
    "    model =        LGBMClassifier(\n",
    "                num_leaves=leaves,\n",
    "                learning_rate=lr,\n",
    "                n_estimators=n_estimators,\n",
    "                min_child_samples=child,\n",
    "                subsample = subsample,\n",
    "                colsample_bytree = colsample,\n",
    "\n",
    "                random_state = seed,\n",
    "                n_jobs = -1\n",
    "            )\n",
    "    model.fit(x_train,y_train,\n",
    "              categorical_feature = cat_cols\n",
    "             \n",
    "             )\n",
    "#     print(model.predict_proba(x_test)[:,1],y_test.values)\n",
    "    score = myscore(model.predict_proba(x_test)[:,1],y_test.values)\n",
    "    \n",
    "    return score\n",
    "\n",
    "space = [Integer(4,100),Integer(1,100),Integer(1,100),Real(0.1,1),Real(0.1,1)]\n",
    "def ask(history,base_estimator,acqfunc, n_suggest):\n",
    "        \n",
    "    optimizer =  Optimizer( space,base_estimator=base_estimator, n_initial_points=1,initial_point_generator='random',\n",
    "                acq_optimizer=\"auto\", random_state=0,\n",
    "                              acq_func=acqfunc\n",
    "                              )\n",
    "    for i in range(len(history)):\n",
    "            config, loss = history[i]\n",
    "            optimizer.tell(config, -loss,\n",
    "                          fit=(i == len(history) - 1)\n",
    "                          )\n",
    "    \n",
    "    a = optimizer.ask(n_suggest)\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_suggest = 3\n",
    "N_round = 50\n",
    "init_num = 10\n",
    "oplist = ['GP','RF','ET','GBRT']\n",
    "acqfunclist = ['LCB','EI','PI','gp_hedge']\n",
    "score_dict = {}\n",
    "for test_bo in  oplist:\n",
    "    for acf in acqfunclist:\n",
    "        score_dict[(test_bo,acf)] = []\n",
    "        for allseed in range(10):\n",
    "            history = [] \n",
    "            \n",
    "            optimizer =  Optimizer( space,base_estimator='GP', n_initial_points=init_num,initial_point_generator='random',\n",
    "            acq_optimizer=\"auto\", random_state=allseed,\n",
    "                          acq_func='EI',\n",
    "                          )\n",
    "            for i in range(init_num):\n",
    "                tmp_ask = optimizer.ask()\n",
    "                tmp_score = f(tmp_ask,allseed)\n",
    "                history.append((tmp_ask,tmp_score))\n",
    "                \n",
    "            for i in tqdm(range(N_round)):\n",
    "                tmp_ask_list = ask(history,base_estimator=test_bo,acqfunc = acf, n_suggest = N_suggest)\n",
    "                tmp_score_list = [f(tmp_ask) for tmp_ask in tmp_ask_list]\n",
    "                history += [(tmp_ask_list[i],tmp_score_list[i]) for i in range(N_suggest)]\n",
    "            score_dict[(test_bo,acf)].append(np.max(tmp_score_list))\n",
    "            print(score_dict)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon = 0.05\n",
    "init_std = 2.0\n",
    "stable = 0.1\n",
    "waterline = 1\n",
    "N_group = 4\n",
    "def get_bo(mydict,history,n_suggest):\n",
    "    score = [h[1] for h in history]\n",
    "    base = np.mean(score)\n",
    "    base_std = np.std(score)\n",
    "    prob = []\n",
    "    bo_acf_list = []\n",
    "    for idx in mydict:\n",
    "        if len(mydict[idx]) == 0:\n",
    "            prob.append(init_std)\n",
    "        else:\n",
    "            prob.append(max(epsilon,(np.max(mydict[idx] - base - waterline) / base_std)))\n",
    "        bo_acf_list.append(idx)\n",
    "    prob = np.array(prob)\n",
    "    prob /= float(np.sum(prob))\n",
    "    prob_cum = np.cumsum(prob)\n",
    "#     print(prob_cum)\n",
    "    group = []\n",
    "    for _ in range(N_group):\n",
    "        x = np.random.random()\n",
    "        for i in range(len(prob_cum)):\n",
    "            if x <= prob_cum[i]:\n",
    "                group.append(bo_acf_list[i])\n",
    "          \n",
    "    res = set()\n",
    "    for i in range(N_group):\n",
    "        if np.random.random() < stable:\n",
    "            res.add(group[i])\n",
    "        else:\n",
    "            for j in range(i+1,N_group):\n",
    "                \n",
    "                res.add((group[i][0],group[j][1]))\n",
    "                res.add((group[j][0],group[i][1]))\n",
    "                \n",
    "    his_set = set()\n",
    "    re_suggest = []\n",
    "    for r in res:\n",
    "        if r[0] not in his_set:\n",
    "            his_set.add(r[0])\n",
    "            re_suggest.append(r)\n",
    "    if len(re_suggest) >= n_suggest:\n",
    "        return list(re_suggest)[:n_suggest]\n",
    "    else:\n",
    "        re_suggest = list(re_suggest)\n",
    "        while len(re_suggest) < n_suggest:\n",
    "            x = np.random.random()\n",
    "            for i in range(len(prob_cum)):\n",
    "                if x <= prob_cum[i]:\n",
    "                    if bo_acf_list[i][0] not in his_set:\n",
    "                        re_suggest.append(bo_acf_list[i])\n",
    "                        his_set.add(bo_acf_list[i][0])\n",
    "        return re_suggest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "myalgo_score = []\n",
    "oplist = ['GP','RF','ET','GBRT']\n",
    "acqfunclist = ['LCB','EI','PI','gp_hedge']\n",
    "for allseed in range(10):\n",
    "    \n",
    "    history = [] \n",
    "    myalgo_score_dict = {\n",
    "        (op,ac):[] for op in oplist for ac in acqfunclist\n",
    "    }\n",
    "\n",
    "    optimizer =  Optimizer( space,base_estimator='GP', n_initial_points=init_num,initial_point_generator='random',\n",
    "    acq_optimizer=\"auto\", random_state=allseed,\n",
    "                  acq_func='EI',\n",
    "                  )\n",
    "    for i in range(init_num):\n",
    "        tmp_ask = optimizer.ask()\n",
    "        tmp_score = f(tmp_ask,allseed)\n",
    "        history.append((tmp_ask,tmp_score))\n",
    "\n",
    "    for i in tqdm(range(N_round)):\n",
    "        res = get_bo(myalgo_score_dict,history,N_suggest)\n",
    "        tmp_ask_list = []\n",
    "        for bo,acf in res:\n",
    "            tmp_ask = ask(history,base_estimator=bo ,acqfunc = acf, n_suggest = 1)\n",
    "            tmp_ask_list.append(tmp_ask[0])\n",
    "        tmp_score_list = [f(tmp_ask) for tmp_ask in tmp_ask_list]\n",
    "        history += [(tmp_ask_list[i],tmp_score_list[i]) for i in range(N_suggest)]\n",
    "        \n",
    "    myalgo_score.append(np.max(tmp_score_list))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
